# =============================================================================
# Ensenia - AI Teaching Assistant Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control!

# =============================================================================
# CLOUDFLARE API CREDENTIALS
# =============================================================================
# Get these from: https://dash.cloudflare.com/profile/api-tokens
# You need:
# 1. API Token with permissions for: Workers AI, D1, Vectorize, KV, R2
# 2. Account ID from dashboard URL or account settings

CLOUDFLARE_API_TOKEN=your_api_token_here
CLOUDFLARE_ACCOUNT_ID=your_account_id

# =============================================================================
# CLOUDFLARE R2 (Object Storage for PDFs)
# =============================================================================
# Setup instructions:
# 1. Go to: https://dash.cloudflare.com/ → R2
# 2. Create bucket: ensenia-hackaton (or your preferred name)
# 3. Click "Manage R2 API Tokens" → Create API Token
# 4. Permissions: Object Read & Write
# 5. Copy: Access Key ID, Secret Access Key, Endpoint URL

CLOUDFLARE_R2_BUCKET=ensenia-hackaton
CLOUDFLARE_R2_ACCESS_KEY=your_r2_access_key_id
CLOUDFLARE_R2_SECRET_KEY=your_r2_secret_access_key
CLOUDFLARE_R2_ENDPOINT=https://your-account-id.r2.cloudflarestorage.com

# =============================================================================
# CLOUDFLARE D1 (SQL Database for chunk metadata)
# =============================================================================
# Setup instructions:
# 1. Go to: https://dash.cloudflare.com/ → Workers & Pages → D1
# 2. Click "Create database"
# 3. Name: ensenia-ministry-db (or your preferred name)
# 4. Copy the Database ID from the dashboard

CLOUDFLARE_D1_DATABASE_ID=your_d1_database_id

# =============================================================================
# CLOUDFLARE VECTORIZE (Vector Database for embeddings)
# =============================================================================
# Setup instructions:
# 1. Go to: https://dash.cloudflare.com/ → Workers & Pages → Vectorize
# 2. Click "Create index"
# 3. Name: ensenia-curriculum-embeddings
# 4. Dimensions: 768 (matches BGE base model)
# 5. Metric: cosine

CLOUDFLARE_VECTORIZE_INDEX=ensenia-curriculum-embeddings

# =============================================================================
# CLOUDFLARE KV (Key-Value Cache)
# =============================================================================
# Setup instructions:
# 1. Go to: https://dash.cloudflare.com/ → Workers & Pages → KV
# 2. Click "Create namespace"
# 3. Name: ensenia-cache
# 4. Copy the Namespace ID

CLOUDFLARE_KV_NAMESPACE_ID=your_kv_namespace_id

# =============================================================================
# CLOUDFLARE WORKER URL (For Backend Integration)
# =============================================================================
# Local development: http://localhost:8787
# Production: https://your-worker.workers.dev

CLOUDFLARE_WORKER_URL=http://localhost:8787
CLOUDFLARE_REQUEST_TIMEOUT=30
CLOUDFLARE_MAX_RETRIES=3
CLOUDFLARE_CACHE_TTL=3600

# =============================================================================
# DATABASE SETTINGS
# =============================================================================
# PostgreSQL connection string for async operations
# Format: postgresql+asyncpg://username:password@host:port/database

DATABASE_URL=postgresql+asyncpg://ensenia:hackathon@localhost:5433/ensenia
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10

# Chat context window (number of messages to keep)
CHAT_CONTEXT_WINDOW=10

# =============================================================================
# ELEVENLABS (Text-to-Speech)
# =============================================================================
# Get API key from: https://elevenlabs.io/
# Voice ID: Use a Chilean Spanish voice for best results

ELEVENLABS_API_KEY=your_elevenlabs_api_key
ELEVENLABS_VOICE_ID=pNInz6obpgDQGcFmaJgB
ELEVENLABS_MODEL_ID=eleven_turbo_v2_5

# Audio format for TTS output
AUDIO_FORMAT=mp3_44100_128

# Voice settings by grade level
VOICE_STABILITY_ELEMENTARY=0.70
VOICE_STABILITY_MIDDLE=0.65
VOICE_STABILITY_HIGH=0.60

VOICE_SPEED_ELEMENTARY=0.85
VOICE_SPEED_MIDDLE=0.95
VOICE_SPEED_HIGH=1.00

# Audio cache configuration
CACHE_MAX_SIZE_MB=500
CACHE_TTL_HOURS=24

# =============================================================================
# OPENAI SETTINGS
# =============================================================================
# Get API key from: https://platform.openai.com/api-keys

OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=5000
OPENAI_TEMPERATURE=0.4

# =============================================================================
# DEEPGRAM (Streaming Speech-to-Text, RECOMMENDED)
# =============================================================================
# Get API key from: https://console.deepgram.com/
# Provides real-time transcription with live results
# Supports 99+ languages including Spanish

DEEPGRAM_API_KEY=your_deepgram_api_key_here


# =============================================================================
# EXERCISE GENERATION SETTINGS
# =============================================================================

# Maximum number of validation iterations in the agent-validator loop
GENERATION_MAX_ITERATIONS=3

# Minimum quality score (0-10) required to accept generated exercise
GENERATION_QUALITY_THRESHOLD=8

# Model to use for exercise generation (can be different from chat model)
GENERATION_MODEL=gpt-4-turbo-preview

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================

# Environment: development | staging | production
ENVIRONMENT=development

# Enable debug mode (shows detailed error messages)
DEBUG=false

# Logging level: DEBUG | INFO | WARNING | ERROR
LOG_LEVEL=INFO

# Cache directory for generated audio and exercises
CACHE_DIR=./cache

# =============================================================================
# API SETTINGS
# =============================================================================

# Host to bind the API server (0.0.0.0 allows external access)
API_HOST=0.0.0.0

# Port for the API server
API_PORT=8000

# CORS allowed origins (comma-separated, no spaces)
# Add your frontend URLs here
API_CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# =============================================================================
# CACHE SETTINGS (in seconds)
# =============================================================================

# Default cache TTL for search results and general queries
CACHE_DEFAULT_TTL=3600

# TTS audio cache TTL (longer since audio files are expensive to generate)
CACHE_TTS_TTL=86400

# =============================================================================
# RAG (Retrieval-Augmented Generation) SETTINGS
# =============================================================================

# Number of top results to retrieve from vector search
RAG_TOP_K=10

# Minimum similarity score for search results (0.0 - 1.0)
RAG_MIN_SIMILARITY_SCORE=0.7

# Text chunk size in characters (for PDF processing)
RAG_CHUNK_SIZE=768

# Overlap between chunks in characters (prevents splitting concepts)
RAG_CHUNK_OVERLAP=128

# =============================================================================
# WORKERS AI SETTINGS
# =============================================================================

# Embedding model for generating vector embeddings
# Options: @cf/baai/bge-base-en-v1.5 (768 dims, recommended)
#          @cf/baai/bge-large-en-v1.5 (1024 dims, more accurate but slower)
WORKERS_AI_EMBEDDING_MODEL=@cf/baai/bge-base-en-v1.5

# Embedding dimensions (must match model: 768 for base, 1024 for large)
WORKERS_AI_EMBEDDING_DIMENSIONS=768

# Workers AI HTTP timeout settings (in seconds)
# These timeouts are critical for processing large text chunks during embedding generation
# Time to establish connection
WORKERS_AI_TIMEOUT_CONNECT=10
# Time to read response from API
WORKERS_AI_TIMEOUT_READ=60
# Time to send request (important for large text chunks)
WORKERS_AI_TIMEOUT_WRITE=120
# Time to acquire connection from pool
WORKERS_AI_TIMEOUT_POOL=10      
